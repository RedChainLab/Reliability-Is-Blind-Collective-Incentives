\section{\sysname\space | Detailed description}\label{sec:solution}

The key to selecting providers such that average round-trip latencies are minimized lies in the design of the \emph{Provider Selection Module}, which is detailed in this section.

\subsection{Available information}

The \emph{Provider Selection Module} has access to the sequences of observed round-trip latencies for each provider $j$, denoted $\{\Delta_{j}=\lbrack \Delta_{j}^{k}\rbrack | j\in\llbracket 1, N_{P}\rrbracket\}$, where $\Delta_{j}^{k}$ is the round-trip latency of the $k$-th request-response exchange between the \emph{Consumer} and \emph{Provider} $j$.
It also maintains the set of selection ratios, i.e, the probabilities to select each provider $j$, denoted $\{ r_{j} | j\in\llbracket 1, N_{P}\rrbracket\}$, such that $\sum_{j\in \llbracket 1,N_{P}\rrbracket}r_{j}=1$.

\subsection{Module design rationales}

As the incoming request load on a given provider increases, the queuing delay at its TEE increases, which in turn increases the round-trip latency for the requests it serves.
This means that a consumer may need to divide its target request throughput among several providers to minimize the average round-trip latency it experiences.
With this objective in mind, and based on currently available information, the \emph{Provider Selection Module} shall tune the selection ratios $\{ r_{j} | j\in\llbracket 1, N_{P}\rrbracket\}$.
In other words, given a provider $j$ and observed round-trip latencies $\Delta_{j}$ for this provider, as well as some scoring function $f$, if $f(\Delta_{j})<\text{avg}_{k\in \llbracket 1,N_{P}\rrbracket}(f(\Delta_{k}))$, i.e., if provider $j$ under-performs compared to the average of all providers, then $r_{j}$ should be decreased. 
Conversely, a higher-than-average score should increase the selection ratio $r_{j}$.
In the following, we will use a sliding-window average of size $s$ as the scoring function $f$, that is, we average the $s$ latest observed latencies. 

\subsection{Submodules description}

The provider selection operates in two distinct operations, the selection itself each time a request should be sent, at step 2 in \Cref{fig:system_arch},
and the update of the selection ratios, which may happen asynchronously to the search mechanism. 
In the implemented solution, the update of the selection ratios happens each time $s$ responses are received, with $s$ the sliding window size used in the ratio update algorithm.

\subsubsection{Provider selection}

At step 2 of the search mechanism (see \Cref{sec:overview} and \Cref{fig:system_arch}), the \emph{Provider Selection Module} selects a provider $j$ with a probability $r_{j}$, where the request will then be sent in step 3.

\subsubsection{Client-side Optimization of Latencies}

In a recurring fashion, e.g., each time $s$ responses are received, the \emph{Provider Selection Module} updates the selection ratios $\{ r_{j}\}$, based on the observed round-trip latencies $\{\Delta_{j}\}$, using \Cref{algo:update_ratios}.

\setlength{\textfloatsep}{0pt}
\begin{algorithm}
    \KwIn{$\{ r_{j}^{in} | j\in\llbracket 1, N_{P}\rrbracket\}$ the initial set of selection ratios for each provider $j$, such that $\sum_{j\in \llbracket 1,N_{P}\rrbracket}r_{j}=1$;
    $\{\Delta_{j}=\lbrack \Delta_{j}^{k}\rbrack | j\in\llbracket 1, N_{P}\rrbracket\}$ the set of sequences of observed round-trip latencies (ordered from newest to oldest latencies) for each provider $j$;
    }
    \KwData{
    $x$ the exploration coefficient;
    $K_{p}$ the PD-controller error-proportional coefficient; $K_{d}$ the PD-controller error-derivative coefficient;
    $s$ the sliding window size
    }
    \KwOut{$\{ r_{j}^{out} | j\in\llbracket 1, N_{P}\rrbracket\}$ the new set of selection ratios for each provider $j$, such that $\sum_{j\in \llbracket 1,N_{P}\rrbracket}r_{j}=1$;}
    
    \Begin{
        $\Delta_{j}^{avg} \leftarrow \frac{1}{s}\sum_{k=1}^{s}\Delta_{j}^{k} \quad \forall j\in\llbracket 1, N_{P}\rrbracket$\;
        $\Delta_{j}^{prev,avg} \leftarrow \frac{1}{s}\sum_{k=s+1}^{2s}\Delta_{j}^{k} \quad \forall j\in\llbracket 1, N_{P}\rrbracket$\;
        $\Delta^{avg} \leftarrow \frac{1}{N_{P}}\sum_{j=1}^{N_{P}}\Delta_{j}^{avg}$\;
    
        \For{$j\in\llbracket 1, N_{P}\rrbracket$}{
            $e_{j} \leftarrow \frac{\Delta^{avg} - \Delta_{j}^{avg}}{\Delta^{avg}}$\;
            $d_{j} \leftarrow \Delta_{j}^{avg} - \Delta_{j}^{prev,avg}$\;
            $r_{j}^{tmp} \leftarrow clamp(r_{j}^{in} + K_{p}e_{j} + K_{d}d_{j}$, 0, 1)\;
        }
    
        \For{$j\in\llbracket 1, N_{P}\rrbracket$}{
            $r_{j}^{norm} \leftarrow \frac{r_{j}^{tmp}}{\sum_{j\in \llbracket 1,N_{P}\rrbracket}r_{j}^{tmp}}$\;
            $r_{j}^{out} \leftarrow (1-x)r_{j}^{norm} + x\frac{1}{N_{P}}$\;
        }
        \Return{$\{ r_{j}^{out} | j\in\llbracket 1, N_{P}\rrbracket\}$}
    }
    \caption{UpdateSelectionRatios}
    \label{algo:update_ratios}
\end{algorithm}

In \Cref{algo:update_ratios}, we use the logic of a PD-controller (Proportional Derivative) to update the selection ratios, with the error-proportional coefficient $K_{p}$ and the error-derivative coefficient $K_{d}$. 
The setpoint, i.e., the target value, for this controller is the average score among all providers, i.e., the average round-trip latency among all providers, $\Delta^{avg}$, in the last $s$ request-response interactions with each provider.
The objective of the controller is to incrementally update selection ratios $r_{j}$ to bring provider-specific average latencies $\Delta_{j}^{avg}$ closer to the global average latency of all providers $\Delta^{avg}$.

In more detail, the algorithm proceeds as follows, and as illustrated by \Cref{algo:update_ratios}.
First, average round-trip times for the current and previous windows are computed for each provider $j$ (lines 2 and 3), as well as the global average round-trip time $\Delta^{avg}$ (line 4), the setpoint of the PD-controller.
Then, for each provider $j$, the error $e_{j}$ with respect to the setpoint and the derivative of the error $d_{j}$ are computed (lines 6 and 7).
$e_{j}$ is the relative difference between the provider $j$'s average latency and the global average latency. 
$d_{j}$ is the difference between the provider $j$'s average latency in the current window and the previous window.
Then, the selection ratio $r_{j}$ is updated using the PD-controller formula, and clamped so the resulting value is the nearest available in the interval $[0,1]$ (line 8).
The selection ratios are normalized (lines 10), i.e., $\sum r_{j} = 1$.
Finally, we remark that this client-side provider selection can be described as a Multi-Armed Bandit problem~\cite{slivkins2019introduction}: a consumer sends a request to a chosen provider $j$ (i.e., pulls lever $j$), and experiences a round-trip latency (i.e., the reward).
The consumer's objective is to maximize its reward: select providers such that it minimizes latencies. 
As is common in Multi-armed bandit settings~\cite{slivkins2019introduction}, the selection policy should allocate a small fraction of requests to explore the latency-performance of each provider, to avoid exploiting sub-optimal providers asymptotically.
This is achieved by mixing a uniform probability of selecting each provider $\frac{1}{N_{P}}$ with the current values of $r_{j}$, weighted by $x$ and $(1-x)$ respectively (line 11).

We draw attention to the fact that the presented algorithm requires calibration of the coefficients $K_{p}$ and $K_{d}$, as well as of the exploration coefficient $x$, so as to offer theoretical guarantees.
This can be online, during the system's operation, with parameter-tuning algorithms~\cite{fiducioso2019safe,xu2023config}. 
Algorithms from the Multi-Armed Bandit literature that tolerate evolving reward distributions, like Exp3~\cite{auer2002nonstochastic}, may also be used. 

As our focus was not on convergence, but on the asymptotic behavior of the system where selection ratios have converged, parameters were tuned using the Zieglerâ€“Nichols method~\cite{ziegler1942optimum}.
We tune the system such that its convergence was near-optimal in micro-benchmark scenarios, i.e., in a set of stereotypical network scenarios (e.g., high- versus low-latency providers; high- versus low-throughput providers), and converged with random topologies drawn from the dataset which will be presented in the next section.
