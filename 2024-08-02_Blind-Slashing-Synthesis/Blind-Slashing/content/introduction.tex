\section{Introduction}

%1 Establish a territory: bring out the importance of the subject and/or make general statements about the subject and/or present an overview on current research on the subject.
%2 Establish a niche: oppose an existing assumption or reveal a research gap or formulate a research question or problem or continue a tradition.
%3 Occupy the niche: sketch the intent of the own work and/or outline important characteristics of the own work; outline important results; and give a brief outlook on the structure of the paper.

%The introduction sets the story of the paper. It can be viewed like a funnel that takes on board all readers with different background, motivation and expectations and leads them to your contribution.
%An introduction has the following parts:
%• The motivation introduces the topic and claims the field. Very short.
%• The problem explains what you want to solve. Examples usually help the reader to create an early, intuitive understanding.
%• The contribution explain your contributions/solutions to the problems.
%Make them explicit, i.e. use a bullet point list. This is the most important part of the introduction.
%• The impact explains why your contribution is relevant

%It engages the reader by telling a story (but not your personal research story)
%• It starts fast and finishes strong
%• It answers the readers key question
%What is the main question addressed by the paper?
%Why is it important right now?
%What are the main contributions of the paper?
%What are the obtained results?
%Why should the reader care?
%• It clearly identifies what your work is by using active, explicit formulations (i.e. "our contribution is...")

Key players in today's e-commerce landscape are logically centralized companies (e.g., Amazon, Alibaba, Ebay).
This centralization of power renders the marketplace vulnerable to attacks~\cite{skim}, failures~\cite{cuthbertsonFacebookUsersReport2021,swearingenWhenAmazonWeb2018}, and undesirable behaviors such as censorship and bias on goods proposed to consumers~\cite{CensorshipGoogle2024,gargSteemitCensoringUsers2019,glaserHowAppleAmazon2017}.

Novel decentralized marketplaces like OpenSea %\footnote{https://opensea.io}
 or Rarible %\footnote{https://rarible.com} 
 aim at solving these problems, notably by using blockchain and decentralized storage (e.g., IPFS~\cite{doan2022towards}) as building blocks. 
In such systems, anyone can offer assets for sale or look up assets to buy.
A match-making algorithm matches buy and sell orders emanating from each side of the market.

A key functionality for enabling buyers to find assets they want to acquire is a search mechanism.
Unfortunately, current decentralized marketplaces either lack an integrated search mechanism (e.g., OpenBazaar%\footnote{https://openbazaar.org}
), % a decentralized alternative to Ebay), 
or use a centralized search mechanism (e.g., OpenSea),
thereby reintroducing risks of censorship and bias. 

In recent years, solutions were proposed to enable decentralized search mechanisms in decentralized marketplaces~\cite{liBringingDecentralizedSearch2021,keizerDittoDecentralisedSimilarity2023,zichichi_towards_2021}.
Notably, DeSearch~\cite{liBringingDecentralizedSearch2021} proposes a multi-keyword search for decentralized services. %In particular, DeSearch enables to preserve trust during the entire search pipeline, from the resources hosted in the blockchain-based marketplace all the way to the response to a consumer query.
It leverages Trusted Execution Environments (Intel SGX~\cite{costan2016intel}) to protect buyers from censorship and bias attacks.
DeSearch relies on a subset of users contributing their computing assets to run the decentralized search protocol and act as service providers. 

\begin{figure}
  \centering

  \includegraphics[scale=0.8]{\figpathmotivation}

  \caption{\emph{Information front-running: without TEEs or without latency-aware provider selection, malicious consumers are able to be more often the first to see new assets} | Share of never-before-seen assets discovered first by malicious consumers ($\frac{50}{100}$ of total consumers), under different configurations. % (from left to right: without TEEs, with TEEs and random provider selection, with COoL-TEE, and in the fault-free case)
  $\frac{6}{12}$ search providers are malicious and the total system load is 50\%, see results in \Cref{sec:results} for a more exhaustive analysis.}% (Dis)advantage arrows pointing away from the 50% line
  \label{fig:motivation}\vspace{-0.5cm}
\end{figure}

In a context where assets are valuable, scarce, and often both, we must ensure that search service providers cannot favor some users and penalize others.
We are particularly interested in the case where service providers manipulate access to knowledge about new assets for some users, thereby giving a head-start to others.
We call this phenomenon an \textit{information front-running} (IFR) attack.
We show in this paper that recent work on decentralized search mechanisms for decentralized marketplaces is vulnerable to IFR attacks:
malicious service providers have the power to delay responses to honest consumers, in favor of malicious consumers, which we highlight as a novel attack in the context of TEEs.
Malicious consumers can accentuate the providers' attack by loading honest providers, increasing those providers' end-to-end latency, so as to steer honest consumers towards malicious consumers who will then attack them.

We illustrate the impact of IFR in \Cref{fig:motivation}: 
in an open system (1st bar) malicious providers and malicious clients can gain significant advantage due to their capacity to perform IFR and content attacks. 
DeSearch (2nd bar) prevents the latter by using TEEs, but is still vulnerable to delay attacks. 
\sysname (3rd bar) prevents delay attacks and is the closest to the behavior of a fault-free system (4th bar).

We propose \sysname, Client-side Optimization of Latencies coupled with TEEs, a mechanism to protect decentralized search systems from highlighted information front-running attacks.
Building upon the DeSearch~\cite{liBringingDecentralizedSearch2021} protocol, \sysname adds a \emph{Provider Selection Module} at the client-side, that selects providers based on past experiences with them, with respect to observed request-response round-trip latencies. 
Consumers are then able to steer away from providers with higher latencies, be it due to network distance or malicious behavior, and send their requests to providers that minimize experienced latencies. 
The proposed solution is client-side for simplicity and deployability: it does not require server-side modifications, coordination, or consensus.

%\sonia[\plannedforlater]{describe how \sysname is evaluated and its main results}
We evaluate \sysname in both a deployed cluster and a simulated environment (source code available~\cite{coolTEEcode}), in network setups featuring homogeneous or heterogeneous latencies between consumers and providers.
We compare the impact of \sysname and related work in an extensive study, in different system configurations and under different attacker strengths.
In particular, we evaluate the competitive advantage (or lack thereof) for a subset of consumers, and overall latency Quality-of-Service.
We show that in networks where latency heterogeneity between users is low, with \sysname, malicious users do not get an edge over others in terms of fresher market state information, as long as there is enough honest computing power to serve all requests. 
We also highlight how high heterogeneity in network latencies between users can give an intrinsic advantage to users who are already close to providers, even without attacks.

The remainder of the paper is structured as follows. 
We present in \Cref{sec:problem_statement} a model of the ecosystem and actors involved in decentralized marketplace search, upon which we then define our threat model. 
\Cref{sec:overview,sec:solution} provide an overview followed by a detailed description of \sysname. 
Next, in \Cref{sec:experimental_protocol,sec:results}, we respectively present our experimental protocol and our results.
In \Cref{sec:related_work}, we present related work, before concluding in \Cref{sec:conclusion}.
