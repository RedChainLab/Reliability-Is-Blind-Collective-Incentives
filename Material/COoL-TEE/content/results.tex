\section{Results}\label{sec:results}

We now present experimental results, aiming to answer our research questions formulated in the previous \Cref{sec:experimental_protocol}.

\subsection{Fault-free setup}\label{ssec:res-FFPL}

To answer \emph{RQ1}, we first evaluate the impact of the provider selection policy in a fault-free setting.
We compare building block overheads on the same-datacenter topology, and the latency Quality-of-Service of selectio policies in the PlanetLab topology, with heteregeneous network latencies between consumers and providers.

\subsubsection{Building block overheads}\label{ssec:res-bbo}
\begin{figure}
    \centering
    \includegraphics[scale=0.75]{\figpathlatthrough}
    \caption{Latency vs. throughput for DeSearch-like and \sysname provider selection (among $N_{P}=4$ providers), based on enabled security features (SGX simulation/hardware mode and Circuit-ORAM~\cite{wangCircuitORAMTightness2015})}
    \label{fig:ff-lat-through}
\end{figure}
\Cref{fig:ff-lat-through} illustrates overheads incurred wrt. the selection policy and enable security features in a fault-free same-datacenter environment.
We measure latency from the time when the request is generated to when the response arrives back at the consumer, i.e., we include the latency due to provider selection algorithm.
Following the notations in \Cref{subsec:search}, we therefore measure: $t_{recv}-t_{gen}=\delta_{PSM}+\Delta^{k}_{i,j}$.
The provider selection policy has a negligible impact on the system's maximum throughput (less than 2\% in each SGX security setup), as well as on the average latency for a given throughput.
This can be explained by the fact that the selection policy is performed at the consumer-side, and so does not impact the provider-side processing throughput.
Moreover, selection ratio updates are performed by \sysname outside of a request's lifecycle (e.g., after reception of 10 responses), and therefore does not impact the request-response latency.
For both selection policies, the actual selection amounts to a weighted random selection of providers, with the weights being the selection ratios (weights are equal for DeSearch-like systems).

Regarding SGX and ORAM security features, compared to ``Simulation'' mode without ORAM, using SGX ``Hardware'' mode causes a 10\% throughput reduction and adds a 1ms latency overhead, while also activating ORAM reduces the maximum throughput by 37.5\% and adds 5ms of latency. 

\subsubsection{Latency Quality-of-Service}\label{ssec:res-lqos}

\begin{figure}
    \centering
    \includegraphics[scale=0.75]{\figpatha}
    \caption{\emph{COoL-TEE's latency-aware provider selection enables lower end-to-end response times than DeSearch-like provider selection} | Cumulative response time quantile distributions, aggregated from 500 runs, in a fault-free environment on the PlanetLab network topology, without TEEs, and a total system load $\rho=25\%$, for different selection policies.}
    \label{fig:ff-woTEE-PLlats}
\end{figure}

We now measure latencies as $t_{recv}-t_{send}$. 
In terms latency-QoS, \sysname~with COoL selection outperforms DeSearch-like selection, as illustrated by \Cref{fig:ff-woTEE-PLlats}: 
COoL selection's median roundtrip response time is better than the 90\% slowest response times with DeSearch-like selection.
Meanwhile, DeSearch-like selection's median response time performs similarly to COoL selection's 25\% slowest response times.
COoL selection policy therefore enables a better latency-QoS than DeSearch-like selection, in a fault-free environment.

\subsection{Adversarial same-datacenter setup}\label{ssec:res-sameDC}

We now run simulations in the same-datacenter setup, for the considered attacks scenarios and provider selection policies, with a varying proportion of malicious providers $p_{M}$.
We also evaluate in this section the impact of scaling out the number of honest providers, and the impact of the Power-of-two load balancing policy~\cite{mitzenmacherPowerTwoChoices2001} at the provider-side.

We evaluate information front-running impacts for different configurations, and divide our analysis in three case studies:
(1) between single- and multiprovider selection policies;
(2) between COoL- and spatial Power-of-two~\cite{panigrahyAnalysisEvaluationProximitybased2022}-based selection policies;
(3) a focus on COoL provider selection subject to the different attacks defined in \Cref{sec:problem_statement}.

\begin{figure*}
    \centering
    \begin{subfigure}{0.49\linewidth}
        \centering
        \includegraphics[scale=0.75]{\figpathcasemulti}
        \subcaption{Impact of TEE \emph{timing attacks} on single-/multi-provider selection}
        \label{fig:byz-sameDC-cs-rw-multi}
    \end{subfigure}
    \begin{subfigure}{0.49\linewidth}
        \centering
        \includegraphics[scale=0.75]{\figpathcasespot}
        \subcaption{Impact of TEE-based attacks on sPoT~\cite{panigrahyAnalysisEvaluationProximitybased2022} and COoL selections}
        \label{fig:byz-sameDC-cs-rw-spot}
    \end{subfigure}
    \caption{Information front-running case-study wrt. competitors in a \emph{timing-attacked} TEE environment | Shares of discovered NBS-assets (averages with standard deviation), aggregated from 100 runs, in a malicious environment in the same datacenter setup with 8 providers, for different system configurations.
    \emph{The closer the values are to 50\%, the better, as it indicates lower malicious information front-running advantage.}
    }
    \label{fig:byz-sameDC}
\end{figure*}

\subsubsection{Multiprovider selection}\label{ssec:res-multi}

We compare multiprovider selection with either DeSearch-like or COoL policies, with varying $k\in \{1,2,8\}$, the number of selection providers per request.
%DeSearch-like single-provider selection ($DeSearch-like-k=1$) is the policy operated by DeSearch~\cite{liBringingDecentralizedSearch2021}.
In this case-study's 8-provider setup, $k=8$ corresponds to a broadcast policy used by a subset of related work protocols~\cite{stathakopoulouAddingFairnessOrder2021,kelkarThemisFastStrong2023}, and is labeled as such in subsequent figures.
\Cref{fig:byz-sameDC-cs-rw-multi} illustrates the information front-running advantage experienced by malicious consumers, that is, their share of dNBSa, for \emph{timing attacks} and in the \emph{fault-free} case.
For all policies, the higher the number $k$ of honest request replicas, the higher the malicious advantage.
However, single-provider COoL selection ($k=1$) outperforms others: as long as $p{M}\leq p_{exodux}^{timing}$, information front-running (IFR) advantage remains within 2\% of the fault-free case at 50\%. 
$p_{exodux}^{timing}$ is the proportion of malicious providers after which there is not enough honest provider throughput to serve all honest requests, in a context with only \emph{provider-side timing attacks}.
Indeed, without cuckoo attacks by consumers, consumers tend to select providers of their faction (either honest or malicious).
When $p{M}> p_{exodus}^{timing}$, this homogeneity is not possible anymore: more and more honest requests are served by malicious providers.
In contrast to single-provider COoL selection, DeSearch-like provider selection with any $k$, as well as COoL multiprovider selection with $k>2$, show a steady information front-running advantage increase wrt. $p_{M}$.

\subsubsection{Provider-side load balancing}\label{ssec:res-spot}

Now, in \Cref{fig:byz-sameDC-cs-rw-spot}, we compare the state-of-the-art spatial Power-of-two~\cite{panigrahyAnalysisEvaluationProximitybased2022} (sPoT) to our proposed solution, first in a \emph{timing-attacked} TEE environment. 
We then also evaluate the impact of the new attack introduced by provider-side load balancing: the \emph{queue attack} coupled with \emph{timing attacks}.

First, with \emph{timing attacks} only and with standalone sPoT~\cite{panigrahyAnalysisEvaluationProximitybased2022}, the share of dNBS-assets by malicious consumers increases steadily with $p_{M}$.
In sPoT, consumers rely on a network distance measurement (e.g., a ping) to determine their two closest providers.
In an adversarial same-datacenter setup, where all providers are roughly equidistant to a given consumer, and can lie about one-shot latency measurements, sPoT amounts to single-provider random selection: ``DeSearch-like-k=1'' in \Cref{fig:byz-sameDC-cs-rw-multi} and ``sPoT'' in \Cref{fig:byz-sameDC-cs-rw-spot} have similar shapes.  
Meanwhile, with consumer-side COoL selection, as well as with its $k=2$ variant augmented with sPoT at the provider-side, the malicious dNBS-asset share remains close as long as $p_{M}\leq p_{exodus}^{timing}$.

However, when we consider the increased attack surface introduced with provider-side load balancing, i.e., 
when malicious providers leverage \emph{queue attacks} on top of \emph{timing} attacks, solutions based on this provider-side balancing suffer more from IFR.
Standalone ``COoL'' selection is client-side only, so this attack vector does not exist.
%To obtain more requests, i.e., increase its selection ratio $r_{j}$, a provider must provide lower latencies than the providers from whom the incoming request load should be taken.

\subsubsection{COoL selection under fire}\label{ssec:cs3}

\begin{figure*}
    \centering
    \begin{subfigure}{0.49\linewidth}
        \centering
        \includegraphics[scale=0.75]{\figpathcaseba}
        \subcaption{Impact of (non-)TEE-based attacks on COoL provider selection with 8 total providers}
        \label{fig:byz-sameDC-cs-8sp}
    \end{subfigure}
    \begin{subfigure}{0.49\linewidth}
        \centering
        \includegraphics[scale=0.75]{\figpathcasebb}
        \subcaption{Impact of (non-)TEE-based attacks on COoL provider selection scaled out with 4 additional honest providers}
        \label{fig:byz-sameDC-cs-12sp}
    \end{subfigure}
    \caption{Information front-running case-study wrt. attack scenarios in (non-)TEE environments | 
    Shares of discovered NBS-assets (averages with standard deviation), aggregated from 100 runs, in a malicious environment in the same datacenter setup, with either 8 or 12 providers (resp. \Cref{fig:byz-sameDC-cs-8sp,fig:byz-sameDC-cs-12sp}) under different attack scenarios.
    \emph{The closer the values are to 50\%, the better, as it indicates lower malicious information front-running advantage.}
    }
    \label{fig:byz-sameDC-cs-att}
\end{figure*}

Finally, \Cref{fig:byz-sameDC-cs-8sp} focuses on single-provider COoL selection Information Front-running (IFR) advantage, when subject to different provider- and consumer-side attacks, still from the point-of-view of dNBSa by malicious consumers. 
\emph{Content-} and \emph{timing-based attacks} show different behaviors: while (cuckoo-)content attacks have the share of dNBSa grow steadily with $p_{M}$, \emph{(cuckoo-)timing attacks} have this share close to the fault-free case, so long as $p_{M}$ is less than the attack-specific threshold $p_{exodus}$.
After their $p_{exodus}$, the IFR advantage rises sharply for each \emph{timing-based attack}.
Note how $p_{exodus}^{cuckoo-T}<p_{exodus}^{timing}$.
Without cuckoo attacks, malicious consumers try to satisfy their latency-minization objective, which drives them towards malicious providers (whom honest consumers avoid).
However, with \emph{cuckoo-timing attacks}, malicious consumers give up this objective in favor of actively loading honest providers.
This why the honest consumers' shift towards malicious providers happens with a lower $p_{M}$, i.e., $p_{exodus}^{cuckoo-T}<p_{exodus}^{timing}$.
Here, in \Cref{fig:byz-sameDC-cs-8sp}, the impact of \emph{cuckoo-timing attacks} for a given $p_{M}$ is similar to a \emph{provider-side-only timing attack} with 3 more malicious providers.
In other words, a lower $p_{M}$ is required for the same IFR advantage, if malicious consumers are willing to trade their latency-minimization objective for an active participation in attacks.

\emph{Timing attacks} require heavily loading honest providers: we evaluate in \Cref{fig:byz-sameDC-cs-12sp} the impact of a scale-out behavior by honest providers in response to high loads: 4 additional honest providers are launched compared to \Cref{fig:byz-sameDC-cs-8sp}.
The incoming consumer load remains the same, such that the total system load $\rho$ goes down from 75\% (with 8 providers in \Cref{fig:byz-sameDC-cs-8sp}) to 50\% (12 providers in \Cref{fig:byz-sameDC-cs-12sp}).
Lessening the total system load $\rho$ increased the attack-thresholds $p_{exodus}^{cuckoo-T}$ and $p_{exodus}^{timing}$: 
while impactful attacks were possible for $p_{M}>25\%$ in the 8-provider setup loaded at $\rho=75\%$, $p_{M}>50\%$ is now necessary in the 12-provider setup loaded at $\rho=50\%$. 
Indeed, $p_{exodus}^{cuckoo-T}$ is tied to $\rho$, in that it marks when honest consumers cannot shoulder the total request load anymore, which gives: $p_{exodus}^{cuckoo-T}= 1-\rho$.
$p_{exodus}^{timing}$ depends on $\rho$, but also on $c_{M}$, because only honest consumers overload honest providers in provider-side-only timing attacks, such that: 
$p_{exodus}^{timing}= 1-(1-c_{M})\rho$.
Note how without TEEs, i.e., under (cuckoo-)content attacks, malicious dNBSa shares are not sensitive to the system load $\rho$: malicious IFR advantage is a function of $p_{M}$ for provider-side content attacks, and of $p_{M}$ and $c_{M}$ with cuckoo-content attacks.
With cuckoo-content attacks, the slope change in \Cref{fig:byz-sameDC-cs-8sp,fig:byz-sameDC-cs-12sp} happens when the proportion of malicious providers is equal to the proportion of honest consumers, that is:
$p_{exodus}^{cuckoo-C-satur}= 1-c_{M}$.
%For cuckoo-content attacks, $p_{exodus}^{cuckoo-C-start}$ is the malicious provider proportion after which the malicious dNBS-asset share starts increasing sharply. 
%Meanwhile, $p_{exodus}^{cuckoo-C-satur}$ marks the slowdown in this dNBS-asset share increase as $p_{M}$ continues to rise, which happens when all honest consumers can be tricked into selecting malicious providers.
%$p_{exodus}^{cuckoo-C-start}$ applies to both content and cuckoo-content attacks, while only cuckoo-content attacks experience the slowdown in share-increase from $p_{exodus}^{cuckoo-C-satur}$ onward.
%$p_{exodus}^{cuckoo-C-start}=0$ in \Cref{fig:byz-sameDC-cs-8sp,fig:byz-sameDC-cs-12sp} as well as in the general case, as long as there are both malicious providers and consumers in the system, i.e., $c_{M}>0$ and $p_{M}>0$.
%Similarly, whatever the system load $\rho$, $p_{exodus}^{cuckoo-C-satur}$ happens when the proportion $p_{M}$ of malicious providers is equal to the proportion of honest consumers, whilst keeping provider-local loads equal to the total system load $\rho$, that is:
%$p_{exodus}^{cuckoo-C-satur}\approx 1-c_{M}$.

\subsubsection{Case-studies summary}
To summarize and answer \emph{RQ2}, in the same-datacenter setup, with COoL provider selection, as long as the honest providers' maximum throughput is sufficient to serve all requests (or all honest requests under \emph{provider-side-only attacks}), \emph{timing-attacked} honest consumers discover NBS-assets at similar rates as malicious consumers.
In practice, this can be ensured using load-aware elasticity mechanisms~\cite{HorizontalPodAutoscaling}: the third case-study in \Cref{ssec:cs3} and \Cref{fig:byz-sameDC-cs-att} show the impact of tuning the system load $\rho$ on the necessary malicious provider proportion $p_{M}$ for impactful attacks.
Meanwhile, without TEEs, or without latency-aware provider selection, dNBSa by malicious consumers increase nearly linearly wrt. the proportion of malicious providers $p_{M}$.

Experiments were also run either with periodic asset arrivals, or periodic inter-request emission delays, but do not illustrate due to lack of space: conclusions drawn above still hold in those cases, albeit with higher standard deviations. 

\subsection{Adversarial PlanetLab setup}\label{ssec:res-malPL}

\begin{figure}
    \centering
    \includegraphics[scale=.75]{\figpathnbsawt}
    \caption{\emph{The staler the response, the less likely NBS-assets will be discovered from it} | Number of NBS-assets discovered with a latency from service start to response reception of $\Delta$ milliseconds, depending on the behavior (honest or malicious) of the sending consumer and handling provider, in a TEE-protected environment, with a total system load $\rho=25\%$, subject to \emph{timing attacks} ($p_{M}=\frac{4}{8}$ providers are malicious), on the PlanetLab network topology.}
    \label{fig:nbsa-wt}
\end{figure}

The choice of $\delta_{att}$, which will in the end impact the probability that honest consumers discover never-before-seen (NBS) assets thanks to malicious providers, depends on the network topology. 
Indeed, the lower the response time to a request, from the moment the response is computed to its reception by the consumer, the higher the expectancy on the number of discovered assets before other consumers thanks to that request. 
Conversely, a high response latency is correlated with rarer NBS-asset discoveries. 
This response time is affected by the actual network latency $\delta_{net}$, but also by the artificial latency $\delta_{att}$, when malicious providers attack honest consumers.
Observing the number of NBS-assets discovered by requests depending on the response time, as illustrated by \Cref{fig:nbsa-wt}, in a \emph{timing-attacked} system, 
shows that an overwhelming majority of NBS-assets are discovered within a 50ms response time, and nearly all within 100ms. 
The dotted lines, dNBSa by honest consumers through malicious providers, are flat at 0 until 50ms, because $\delta_{att}=50ms$: no response can arrive before that. 
A very slight increase exists after 50ms, due to honest consumers that were collocated or close to malicious providers in some runs, 
but it remains negligible compared to what other combinations of consumer and provider behaviors were able to discover.
The value of $\delta_{att}$ in experiments was chosen based on this observation.

Regarding dNBS-assets by honest and malicious consumers, due to lack of space, we illustrate the results in heterogeneous-latency networks by comparison with \Cref{fig:byz-sameDC-cs-8sp,fig:byz-sameDC-cs-rw-multi}'s same-datacenter setup results.
Compared to the same-datacenter setup, the observed shares of dNBS-assets discovered by a given consumer type (honest or malicious) are similar for any provider selection under \emph{content attacks}, ``DeSearch-like-k=1'' selection under \emph{timing attacks}, and in the fault-free case, but with higher variance, due to the latency-heterogeneity between runs. 
However, a notable difference is that COoL selection under \emph{timing attacks} now behaves similarly to the other two attacked configurations. 
Deeper analysis shows that consumers do indeed send most requests to their closest providers, but network latencies are such that if the closest provider is malicious, the next closest honest provider is sometimes too far away to compensate: to yield fresh enough responses and, consequently, enough NBS-assets. 
%Meanwhile, malicious consumers are served nominally by all providers: this disparity explains why optimizing latencies was not sufficient to counteract \emph{timing attacks} in the PlanetLab setup, unlike in the same-datacenter setup.

Finally, to answer \emph{RQ3}, we have shown that in a topology with heterogeneous latencies between pairs of consumer-providers, the position of a consumer in the topology highly impacts their chance at discovering NBS-assets, whatever the selection policy.
This is especially true for honest consumers, which, if they use COoL selection and their closest providers are \emph{malicious}, may be subject to an attack $\delta_{att}$ up to the latency difference between these \emph{malicious} providers and their next-closest \emph{honest} provider.
Should they use DeSearch-like selection instead, then malicious providers can attack them with an arbitrarily high $\delta_{att}$, yielding even fewer dNBSa.
